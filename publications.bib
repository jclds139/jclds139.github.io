@article{henrie.etal2018HardwareSoftware,
  title = {Hardware and Software Improvements to a Low-Cost Horizontal Parallax Holographic Video Monitor},
  author = {Henrie, Andrew and Codling, Jesse R. and Gneiting, Scott and Christensen, Justin B. and Awerkamp, Parker and Burdette, Mark J. and Smalley, Daniel E.},
  year = {2018},
  month = jan,
  journal = {Applied Optics},
  volume = {57},
  number = {1},
  pages = {A122},
  issn = {1559-128X, 2155-3165},
  doi = {10.1364/ao.57.00a122},
  urldate = {2025-09-11},
  langid = {english},
  language = {en},
  keywords = {Holography,Journal,nosource},
  annotation = {ZSCC: 0000002}
}
% == BibTeX quality report for henrie.etal2018HardwareSoftware:
% ? unused Journal abbreviation ("Appl. Opt.")
% ? unused Library catalog ("CrossRef")
% ? unused Url ("https://www.osapublishing.org/abstract.cfm?URI=ao-57-1-A122")

@inproceedings{asod,
  title = {Demo Abstract: Active Structural Occupant Detector},
  shorttitle = {Demo Abstract},
  booktitle = {2020 19th {{ACM}}/{{IEEE International Conference}} on {{Information Processing}} in {{Sensor Networks}} ({{IPSN}})},
  author = {Codling, Jesse R and Mirshekari, Mostafa and Noh, Hae Young and Zhang, Pei},
  year = {2020},
  month = apr,
  pages = {353--354},
  publisher = {IEEE},
  address = {Sydney, Australia},
  doi = {10.1109/IPSN48710.2020.00-10},
  urldate = {2025-09-11},
  copyright = {https://ieeexplore.ieee.org/Xplorehelp/downloads/license-information/IEEE.html},
  isbn = {978-1-7281-5497-8},
  langid = {english},
  language = {en},
  keywords = {Poster/Demo},
  file = {/home/jesse/Zotero/storage/2R93BFY7/Codling et al_2020_Demo Abstract.pdf;/home/jesse/Zotero/storage/B4RE8I6D/references.html}
}
% == BibTeX quality report for asod:
% ? Unsure about the formatting of the booktitle
% ? unused Library catalog ("DOI.org (Crossref)")

@inproceedings{pignet,
  title = {{{PigNet}}: Failure-Tolerant Pig Activity Monitoring System Using Structural Vibration},
  shorttitle = {{{PigNet}}},
  booktitle = {Proceedings of the 20th {{International Conference}} on {{Information Processing}} in {{Sensor Networks}} (Co-Located with {{Cps-iot Week}} 2021)},
  author = {Bonde, Amelie and Codling, Jesse R. and Naruethep, Kanittha and Dong, Yiwen and Siripaktanakon, Wachirawich and Ariyadech, Sripong and Sangpetch, Akkarit and Sangpetch, Orathai and Pan, Shijia and Noh, Hae Young and Zhang, Pei},
  year = {2021},
  month = may,
  pages = {1--13},
  publisher = {ACM},
  address = {Nashville TN USA},
  doi = {10.1145/3412382.3458902},
  urldate = {2025-09-11},
  copyright = {All rights reserved},
  isbn = {978-1-4503-8098-0},
  langid = {english},
  language = {en},
  keywords = {feature,Fully-Reviewed Conference,Pigs Project},
  file = {/home/jesse/Zotero/storage/GC3VM52G/Bonde et al_2021_PigNet.pdf}
}
% == BibTeX quality report for pignet:
% ? unused Conference name ("IPSN '21: The 20th International Conference on Information Processing in Sensor Networks")
% ? unused Library catalog ("DOI.org (Crossref)")

@inproceedings{MassHog,
  title = {{{MassHog}}: Weight-Sensitive Occupant Monitoring for Pig Pens Using Actuated Structural Vibrations},
  shorttitle = {{{MassHog}}},
  booktitle = {Adjunct {{Proceedings}} of the 2021 {{ACM International Joint Conference}} on {{Pervasive}} and {{Ubiquitous Computing}} and {{Proceedings}} of the 2021 {{ACM International Symposium}} on {{Wearable Computers}}},
  author = {Codling, Jesse R and Bonde, Amelie and Dong, Yiwen and Cao, Siyi and Sangpetch, Akkarit and Sangpetch, Orathai and Noh, Hae Young and Zhang, Pei},
  year = {2021},
  month = sep,
  series = {{{UbiComp}} '21},
  pages = {600--605},
  publisher = {Association for Computing Machinery},
  address = {New York, NY, USA},
  doi = {10.1145/3460418.3480414},
  urldate = {2025-09-11},
  abstract = {In the swine livestock industry, weight tracking is commonly used to track health and growth of pigs. This is especially crucial during the farrowing period, where mother sows and their newborn piglets are housed together to facilitate nursing. Existing weight measurement methods, however, either provide only sporadic snapshots or have scalability and reliability issues in the harsh environment of industrial farms. This paper presents MassHog, a multi-layered system for ubiquitous weight measurement in harsh environments, such as pig pens, using structural vibrations. MassHog combines an existing sensor concept with actuated vibrations to weigh both piglets and adult hogs together. We evaluate the components of this system through testing deployments, including at real-world operating pig farms. Preliminary results show less than 2 kg mean absolute error for adult hogs.},
  copyright = {All rights reserved},
  isbn = {978-1-4503-8461-2},
  langid = {english},
  language = {en},
  keywords = {Pigs Project,Workshop},
  file = {/home/jesse/Zotero/storage/FA53PEM8/Codling et al_2021_MassHog.pdf}
}
% == BibTeX quality report for MassHog:
% ? unused Conference name ("UbiComp '21: The 2021 ACM International Joint Conference on Pervasive and Ubiquitous Computing")
% ? unused Library catalog ("ACM Digital Library")
% ? unused Url ("https://doi.org/10.1145/3460418.3480414")

@inproceedings{codling.etal2022SowPosture,
  title = {Sow Posture and Feeding Activity Monitoring in a Farrowing Pen Using Ground Vibration},
  booktitle = {{{ECPLF}} 2022 - 10th {{European Conference}} on {{Precision Livestock Farming}}},
  author = {Codling, Jesse R and Dong, Yiwen and Bonde, Amelie and Bannis, Adeola and Macon, Asya and Rohrer, Gary and Miles, Jeremy and Sharma, Sudhendu and {Brown-Brandl}, Tami and Noh, Hae Young and Zhang, Pei},
  year = {2022},
  month = aug,
  address = {Vienna, Austria},
  abstract = {Automated monitoring of sow welfare and behaviors is a crucial tool in precision swine farming, giving farmers access to continuous streams of sow health information. Monitoring the activity of the sows helps farmers detect stress, sickness and signs of farrowing, which enables the farmers to provide timely care. Prior work in swine monitoring frequently uses video cameras, which have lighting and large storage and processing requirements. Alternatively, other work has used wearable sensors, which have limited longevity due to durability and battery requirements and suffer from scalability challenges due to the need for individual sensors worn by each sow. The objective of the study was to determine the effectiveness of geophone sensors mounted under the floor that measure the structural vibration of a farrowing pen to determine posture changes and animal feeding activity. A total of 6 farrowing/lactating sows and litters have been used in these studies. The data were collected from a minimum of 3 days before farrowing to approximately 25 days post-farrow. Up to five geophones were used for activity classification. Machine learning classification methods are used to detect the position and feeding activity of the sow and her piglets, including tree classifiers and principal component analysis. Accuracies of over 95\% were achieved in sow posture and feeding activity classification, indicating the potential of monitoring  ground vibration as a source of health information.},
  copyright = {All rights reserved},
  langid = {english},
  language = {en},
  keywords = {Conference,GeoMCU,Pigs Project},
  file = {/home/jesse/Zotero/storage/8BDIYEEP/Codling et al. - 2022 - Sow Posture and Feeding Activity Monitoring in a F.pdf}
}
% == BibTeX quality report for codling.etal2022SowPosture:
% ? Unsure about the formatting of the booktitle
% ? unused Conference name ("10th European Conference on Precision Livestock Farming")

@inproceedings{SeatBeats,
  title = {Poster Abstract: {{SeatBeats}} Heart Rate Monitoring System Using Structural Seat Vibrations},
  shorttitle = {Poster Abstract},
  booktitle = {2022 21st {{ACM}}/{{IEEE International Conference}} on {{Information Processing}} in {{Sensor Networks}} ({{IPSN}})},
  author = {Codling, Jesse R and Cohen, Luke F and Kalivarapu, Venkata Ganesh and Noh, Hae Young and Zhang, Pei},
  year = {2022},
  month = may,
  pages = {511--512},
  publisher = {IEEE},
  address = {Milano, Italy},
  doi = {10.1109/IPSN54338.2022.00056},
  urldate = {2025-09-11},
  abstract = {Monitoring cardiovascular risk factors requires a method for con-tinuous heart rate monitoring. However, this typically relies on a wearable device which must be issued to, then charged and worn by the user. Ambient sensors can address these challenges, but have only been usable in scenarios where the body is in proximity or contact with these sensors, such as on a bed. In this paper, we present SeatBeats, a system that can monitor heart rate using ambient vibrations in the surface a user sits on. The system relies on the surface's response to heart beat-induced vibrations and utilizes autocorrelation to capture and extract the repeated pattern beats. Our experiments in a real office environment show up to 96\% accuracy relative to a smartwatch heart rate sensor.},
  copyright = {All rights reserved},
  isbn = {978-1-6654-9624-7},
  langid = {english},
  language = {en},
  keywords = {Heart Rate,Poster/Demo},
  file = {/home/jesse/Zotero/storage/C3HF6TSE/Codling et al. - 2022 - Poster Abstract SeatBeats Heart Rate Monitoring S.pdf;/home/jesse/Zotero/storage/HAQ9QIQK/9826011.html}
}
% == BibTeX quality report for SeatBeats:
% ? Unsure about the formatting of the booktitle
% ? unused Library catalog ("IEEE Xplore")
% ? unused Url ("https://ieeexplore.ieee.org/document/9826011/")

@inproceedings{PigV2,
  title = {{{PigV2}}: Monitoring Pig Vital Signs through Ground Vibrations Induced by Heartbeat and Respiration},
  shorttitle = {{{PigV2}}},
  booktitle = {Proceedings of the 20th {{ACM Conference}} on {{Embedded Networked Sensor Systems}}},
  author = {Dong, Yiwen and Codling, Jesse R and Rohrer, Gary and Miles, Jeremy and Sharma, Sudhendu and {Brown-Brandl}, Tami and Zhang, Pei and Noh, Hae Young},
  year = {2023},
  month = jan,
  series = {{{SenSys}} '22},
  pages = {1102--1108},
  publisher = {Association for Computing Machinery},
  address = {New York, NY, USA},
  doi = {10.1145/3560905.3568416},
  urldate = {2025-09-11},
  abstract = {Pig vital sign monitoring (e.g., estimating the heart rate (HR) and respiratory rate (RR)) is essential to understand the stress level of the sow and detect the onset of parturition. It helps to maximize peri-natal survival and improve animal well-being in swine production. The existing approach mainly relies on manual measurement, which is labor-intensive and only provides a few points of information. Other sensing modalities such as wearables and cameras are developed to enable more continuous measurement, but are still limited due to animal discomfort, data transfer, and storage challenges. In this paper, we introduce PigV2, the first system to monitor pig heart rate and respiratory rate through ground vibrations. Our approach leverages the insight that both heartbeat and respiration generate ground vibrations when the sow is lying on the floor. We infer vital information by sensing and analyzing these vibrations. The main challenge in developing PigV2 is the overlap of vital- and non-vital-related information in the vibration signals, including pig movements, pig postures, pig-to-sensor distances, and so on. To address this issue, we first characterize their effects, extract their current status, and then reduce their impact by adaptively interpolating vital rates over multiple sensors. PigV2 is evaluated through a real-world deployment with 30 pigs. It has 3.4\% and 8.3\% average errors in monitoring the HR and RR of the sows, respectively.},
  copyright = {All rights reserved},
  isbn = {978-1-4503-9886-2},
  langid = {english},
  language = {en},
  keywords = {Fully-Reviewed Conference,Heart Rate,Pigs Project},
  file = {/home/jesse/Zotero/storage/B9KD7B8R/Dong et al. - 2023 - PigV2 Monitoring Pig Vital Signs through Ground V.pdf}
}
% == BibTeX quality report for PigV2:
% ? unused Conference name ("SenSys '22: The 20th ACM Conference on Embedded Networked Sensor Systems")
% ? unused Library catalog ("ACM Digital Library")
% ? unused Url ("https://doi.org/10.1145/3560905.3568416")

@inproceedings{FreePulse,
  ids = {codling.etal2023DemoAbstract},
  title = {Demo Abstract: {{FreePulse}} Heart Rate Monitoring System Using Ambient Structural Vibrations},
  shorttitle = {{{FreePulse}}},
  booktitle = {The 22nd {{International Conference}} on {{Information Processing}} in {{Sensor Networks}}},
  author = {Codling, Jesse R and Shulkin, Jeffrey D and Dong, Yiwen and Zhang, Jiale and Latapie, Hugo and Noh, Hae Young and Zhang, Pei},
  year = {2023},
  month = may,
  series = {{{IPSN}} '23},
  pages = {364--365},
  publisher = {Association for Computing Machinery},
  address = {San Antonio TX USA},
  doi = {10.1145/3583120.3589812},
  urldate = {2025-09-11},
  abstract = {Heart rate is a critical metric for human cardiovascular health. Most common methods for measuring human heart rate involve wearable devices (e.g., electrocardiography, smart watches). However, such devices can cause discomfort to some patients, especially the elderly or young children. This paper presents FreePulse, a heart rate monitoring system for seated subjects using ambient vibrations. FreePulse builds on our past work using vibrations in the building structures around us to measure human activities and health. As people's hearts beat, they push on the surfaces the body is touching, creating vibrations in those structures. We combine structure response characterization with human pulse modelling to identify these pulse-induced vibrations from ambient vibration. In testing, FreePulse has shown up to 96\% pulse rate accuracy on average, competitive with consumer-grade wearable devices.},
  copyright = {All rights reserved},
  isbn = {979-8-4007-0118-4},
  langid = {english},
  language = {en},
  keywords = {Heart Rate,Poster/Demo},
  file = {/home/jesse/Zotero/storage/WL6BVLNG/Codling et al. - 2023 - Demo Abstract FreePulse Heart Rate Monitoring Sys.pdf}
}
% == BibTeX quality report for FreePulse:
% ? Unsure about the formatting of the booktitle
% ? unused Conference name ("IPSN '23: The 22nd International Conference on Information Processing in Sensor Networks")
% ? unused Library catalog ("ACM Digital Library")
% ? unused Url ("https://dl.acm.org/doi/10.1145/3583120.3589812")

@inproceedings{zhang.etal2023VibrationObjectClass,
  title = {Poster Abstract: Vibration-Based Object Classification with Structural Response of Ambient Music},
  shorttitle = {Poster Abstract},
  booktitle = {Proceedings of the 22nd {{International Conference}} on {{Information Processing}} in {{Sensor Networks}}},
  author = {Zhang, Jiale and Pati, Shweta and Codling, Jesse and Bannis, Adeola and Ruiz, Carlos and Noh, Hae Young and Zhang, Pei},
  year = {2023},
  month = may,
  series = {{{IPSN}} '23},
  pages = {314--315},
  publisher = {Association for Computing Machinery},
  address = {New York, NY, USA},
  doi = {10.1145/3583120.3589825},
  urldate = {2025-09-11},
  abstract = {Object classification is a vital technology that is widely used to track and identify misplaced and out-of-stock items in shopping centers. While there have been a number of studies utilizing various sensing modalities such as computer vision, RFID, and vibration sensors, these methods are limited in their use due to privacy concerns, scalability, and the inability to identify stationary objects. To overcome these limitations, we propose a novel active vibration-sensing approach for object classification by utilizing music as an excitation source. Different objects can induce different deformations of the surface and further change the surface structural response. Therefore, we leverage vibrations from music on a store shelf and measure the structural responses on the surface when different objects are placed. Our evaluation of a store shelf demonstrates that distinct object characteristics lead to unique vibration responses, enabling accurate classification of 98.6\% accuracy in distinguishing five common store objects. This study provides a promising avenue for a reliable, privacy-preserving, and scalable object classification system in various settings beyond shopping centers.},
  copyright = {All rights reserved},
  isbn = {979-8-4007-0118-4},
  langid = {english},
  language = {en},
  keywords = {GeoMCU,Poster/Demo},
  file = {/home/jesse/Zotero/storage/P8SLMAH9/Zhang et al. - 2023 - Poster Abstract Vibration-Based Object Classifica.pdf}
}
% == BibTeX quality report for zhang.etal2023VibrationObjectClass:
% ? unused Conference name ("IPSN '23: The 22nd International Conference on Information Processing in Sensor Networks")
% ? unused Library catalog ("ACM Digital Library")
% ? unused Url ("https://dl.acm.org/doi/10.1145/3583120.3589825")

@article{pigsense,
  title = {{{PigSense}}: Structural Vibration-Based Activity and Health Monitoring System for Pigs},
  shorttitle = {{{PigSense}}},
  author = {Dong, Yiwen and Bonde, Amelie and Codling, Jesse R and Bannis, Adeola and Cao, Jinpu and Macon, Asya and Rohrer, Gary and Miles, Jeremy and Sharma, Sudhendu and {Brown-Brandl}, Tami and Sangpetch, Akkarit and Sangpetch, Orathai and Zhang, Pei and Noh, Hae Young},
  year = {2023},
  month = jun,
  journal = {ACM Transactions on Sensor Networks},
  volume = {20},
  number = {1},
  pages = {1--43},
  issn = {1550-4859},
  doi = {10.1145/3604806},
  urldate = {2025-09-11},
  abstract = {Precision Swine Farming has the potential to directly benefit swine health and industry profit by automatically monitoring the growth and health of pigs. We introduce the first system to use structural vibration to track animals, and the first system for automated characterization of piglet group activities, including nursing, sleeping, and active times. PigSense uses physical knowledge of the structural vibration characteristics caused by pig-activity-induced load changes to recognize different behaviors of the sow and piglets. In order for our system to survive the harsh environment of the farrowing pen for three months, we designed simple, durable sensors for physical fault tolerance, then installed many of them, pooling their data to achieve algorithmic fault tolerance even when some do stop working. The key focus of this work was to create a robust system that can withstand challenging environments, has limited installation and maintenance requirements, and uses domain knowledge to precisely detect a variety of swine activities in noisy conditions while remaining flexible enough to adapt to future activities and applications. We provided an extensive analysis and evaluation of all-round swine activities and scenarios from our 1-year field deployment across two pig farms in Thailand and the USA. To help assess the risk of crushing, farrowing sicknesses, and poor maternal behaviors, PigSense achieves an average of 97.8\% and 94\% for sow posture and motion monitoring, respectively, and an average of 96\% and 71\% for ingestion and excretion detection. To help farmers monitor piglet feeding, starvation, and illness, PigSense achieves an average of 87.7\%, 89.4\%, and 81.9\% in predicting different levels of nursing, sleeping, and being active, respectively. In addition, we show that our monitoring of signal energy changes allows the prediction of farrowing in advance, as well as status tracking during the farrowing process and on the occasion of farrowing issues. Furthermore, PigSense also predicts the daily pattern and weight gain in the lactation cycle with 89\% accuracy, a metric that can be used to monitor the piglets' growth progress over the lactation cycle.},
  copyright = {All rights reserved},
  langid = {english},
  language = {en},
  keywords = {GeoMCU,Journal,Pigs Project},
  annotation = {Just Accepted},
  file = {/home/jesse/Zotero/storage/3U5CAUJ9/Dong et al. - 2023 - PigSense Structural Vibration-based Activity and .pdf}
}
% == BibTeX quality report for pigsense:
% ? unused Journal abbreviation ("ACM Trans. Sens. Netw.")
% ? unused Library catalog ("ACM Digital Library")
% ? unused Url ("https://dl.acm.org/doi/10.1145/3604806")

@inproceedings{GameVibes,
  ids = {dong.etal2023GameVibesVibrationbased},
  title = {{{GameVibes}}: Vibration-Based Crowd Monitoring for Sports Games through Audience-Game-Facility Association Modeling},
  shorttitle = {{{GameVibes}}},
  booktitle = {Proceedings of the 10th {{ACM International Conference}} on {{Systems}} for {{Energy-efficient Buildings}}, {{Cities}}, and {{Transportation}}},
  author = {Dong, Yiwen and Wu, Yuyan and Codling, Jesse R and Aggarwal, Jatin and Huang, Peide and Ding, Wenhao and Latapie, Hugo and Zhang, Pei and Noh, Hae Young},
  year = {2023},
  month = nov,
  series = {{{BuildSys}} '23},
  pages = {177--188},
  publisher = {Association for Computing Machinery},
  address = {Istanbul Turkey},
  doi = {10.1145/3600100.3623750},
  urldate = {2025-09-11},
  abstract = {Crowd monitoring involves tracking and analyzing the behavior of large groups of people in large-scale public spaces, such as sports games. In sports stadiums, understanding audience reactions to the games and their distribution around the public facilities is important for ensuring public safety and security, enhancing the game experience, and improving crowd management. Recent crowd-crushing incidents (e.g., Kanjuruhan Stadium disaster, Seoul Halloween Stampede) have caused 100+ deaths in a single event, calling for advancements in crowd monitoring methods. Existing monitoring approaches include manual observation, wearables, video-, audio-, and WiFi-based sensing. However, few meet the practical needs due to their limitations in cost, privacy protection, and accuracy. In this paper, we introduce GameVibes, a novel method for crowd behavior monitoring using crowd-induced floor vibrations to infer audience reactions to the game (e.g., clapping, stomping, dancing) and crowd traffic (i.e., the number of people entering each door). The main benefits of GameVibes are that it allows continuous, fine-grained crowd monitoring in a cost-effective and non-intrusive way and is perceived as more privacy-friendly. Unlike monitoring an individual person, crowd monitoring involves understanding the overall behavior of a large population (typically more than 1,000), leading to high uncertainty in the vibration data. To overcome the challenge, we first establish the game and facility association to inform the context of crowd behaviors, including 1) game associations (temporal context) between the crowd reaction and the game progress and 2) facility associations (spatial context) between the crowd traffic and facility layouts. Then, we formulate the crowd monitoring problem by converting the conceptual graph of the audience-game-facility association into probabilistic game/facility association models. Through these models, GameVibes first learns the latent representations of the game progress and facility layout through neural network encoders, and then integrates heterogeneous game/facility information and vibration data to estimate crowd behaviors. This mitigates the estimation error due to the uncertainty in vibration data. To evaluate our approach, we conduct 6 real-world deployments for NCAA Pac-12 games at Stanford Maples Pavilion. Our results show that GameVibes achieves a 0.9 F-1 score in crowd reaction monitoring and 9.3 mean absolute error in crowd traffic estimation, which correspond to 10\% and 12.2\% error reduction, respectively, compared to the baseline methods without context-specific information.},
  isbn = {979-8-4007-0230-3},
  langid = {english},
  language = {en},
  keywords = {feature,Fully-Reviewed Conference,GeoMCU,Stadiums},
  file = {/home/jesse/Zotero/storage/VJUTPX2W/Dong et al. - 2023 - GameVibes Vibration-based Crowd Monitoring for Sp.pdf}
}
% == BibTeX quality report for GameVibes:
% ? unused Conference name ("BuildSys '23: The 10th ACM International Conference on Systems for Energy-Efficient Buildings, Cities, and Transportation")
% ? unused Library catalog ("ACM Digital Library")
% ? unused Url ("https://dl.acm.org/doi/10.1145/3600100.3623750")

@inproceedings{fernandez.etal2024PosterDriveby,
  ids = {fernandez.etal2024PosterDrivebya,fernandez.etal2024PosterDrivebyb},
  title = {Poster: Drive-by City Wide Trash Sensing for Neighborhood Sanitation Need},
  shorttitle = {Poster},
  booktitle = {Proceedings of the 22nd {{Annual International Conference}} on {{Mobile Systems}}, {{Applications}} and {{Services}}},
  author = {Fernandez, Tomas and Chang, Yen Cheng and Codling, Jesse and Dong, Yiwen and Zhang, Jiale and {Joe-Wong}, Carlee and Noh, Hae Young and Zhang, Pei},
  year = {2024},
  month = jun,
  series = {{{MOBISYS}} '24},
  pages = {704--705},
  publisher = {Association for Computing Machinery},
  address = {New York, NY, USA},
  doi = {10.1145/3643832.3661431},
  urldate = {2025-09-11},
  abstract = {Computer vision has been used more ubiquitously in recent years to understand and measure the environment around us, particularly in our neighborhoods. However, many city-wide sensing applications using vision require large labeling efforts, making various applications difficult on a wide scale. We propose a framework for labeling and self-training of in-car video to detect trash on the roads. Our approach requires minimal manual labeling to identify items not meant to be in the street, sidewalk, or public places, from a front-viewing car camera. Our system provides each frame of a video with a score indicating the amount of trash. To prevent overfitting, due to minimal available data, we remove data with high certainty of trash from the training dataset. The results show that our prediction with manually labeled ground truth yield an R2 of 0.66.},
  copyright = {All rights reserved},
  isbn = {979-8-4007-0581-6},
  langid = {english},
  language = {en},
  keywords = {julia,nosource,Poster/Demo},
  file = {/home/jesse/Zotero/storage/F3GSXWNJ/Fernandez et al. - 2024 - Poster Drive-by City Wide Trash Sensing for Neigh.pdf}
}
% == BibTeX quality report for fernandez.etal2024PosterDriveby:
% ? unused Conference name ("MOBISYS '24: 22nd Annual International Conference on Mobile Systems, Applications and Services")
% ? unused Library catalog ("ACM Digital Library")
% ? unused Url ("https://dl.acm.org/doi/10.1145/3643832.3661431")

@article{dong.etal2024AmbientFloor,
  title = {Ambient Floor Vibration Sensing Advances the Accessibility of Functional Gait Assessments for Children with Muscular Dystrophies},
  author = {Dong, Yiwen and Iammarino, Megan and Liu, Jingxiao and Codling, Jesse and Fagert, Jonathon and Mirshekari, Mostafa and Lowes, Linda and Zhang, Pei and Noh, Hae Young},
  year = {2024},
  month = may,
  journal = {Scientific Reports},
  volume = {14},
  number = {1},
  pages = {10774},
  publisher = {Nature Publishing Group},
  issn = {2045-2322},
  doi = {10.1038/s41598-024-60034-5},
  urldate = {2025-09-11},
  abstract = {Muscular dystrophies (MD) are a group of genetic neuromuscular disorders that cause progressive weakness and loss of muscles over time, influencing 1 in 3500--5000 children worldwide. New and exciting treatment options have led to a critical need for a clinical post-marketing surveillance tool to confirm the efficacy and safety of these treatments after individuals receive them in a commercial setting. For MDs, functional gait assessment is a common approach to evaluate the efficacy of the treatments because muscle weakness is reflected in individuals' walking patterns. However, there is little incentive for the family to continue to travel for such assessments due to the lack of access to specialty centers. While various existing sensing devices, such as cameras, force plates, and wearables can assess gait at home, they are limited by privacy concerns, area of coverage, and discomfort in carrying devices, which is not practical for long-term, continuous monitoring in daily settings. In this study, we introduce a novel functional gait assessment system using ambient floor vibrations, which is non-invasive and scalable, requiring only low-cost and sparsely deployed geophone sensors attached to the floor surface, suitable for in-home usage. Our system captures floor vibrations generated by footsteps from patients while they walk around and analyzes such vibrations to extract essential gait health information. To enhance interpretability and reliability under various sensing scenarios, we translate the signal patterns of floor vibration to pathological gait patterns related to MD, and develop a hierarchical learning algorithm that aggregates insights from individual footsteps to estimate a person's overall gait performance. When evaluated through real-world experiments with 36 subjects (including 15 patients with MD), our floor vibration sensing system achieves a 94.8\% accuracy in predicting functional gait stages for patients with MD. Our approach enables accurate, accessible, and scalable functional gait assessment, bringing MD progressive tracking into real life.},
  copyright = {2024 The Author(s)},
  langid = {english},
  language = {en},
  keywords = {Gait,GeoMCU,Journal},
  file = {/home/jesse/Zotero/storage/CUACF48X/Dong et al. - 2024 - Ambient floor vibration sensing advances the acces.pdf}
}
% == BibTeX quality report for dong.etal2024AmbientFloor:
% ? unused Journal abbreviation ("Sci. Rep.")
% ? unused Library catalog ("www.nature.com")
% ? unused Url ("https://www.nature.com/articles/s41598-024-60034-5")

@inproceedings{chang.etal2024PosterAbstract,
  ids = {chang.etal2024PosterAbstracta},
  title = {Poster Abstract: Listen and Then Sense: Vibration-Based Sports Crowd Monitoring by Pre-Training with Public Audio Datasets},
  shorttitle = {Poster Abstract},
  booktitle = {2024 23rd {{ACM}}/{{IEEE International Conference}} on {{Information Processing}} in {{Sensor Networks}} ({{IPSN}})},
  author = {Chang, Yen Cheng and Codling, Jesse and Dong, Yiwen and Zhang, Jiale and Shulkin, Jeffrey and Latapie, Hugo and {Joe-Wong}, Carlee and Noh, Hae Young and Zhang, Pei},
  year = {2024},
  month = may,
  pages = {285--286},
  publisher = {IEEE},
  address = {Hong Kong},
  doi = {10.1109/IPSN61024.2024.00043},
  urldate = {2025-09-11},
  copyright = {https://doi.org/10.15223/policy-029},
  isbn = {979-8-3503-6201-5},
  langid = {english},
  language = {en},
  keywords = {crowd monitoring,floor vibration,Poster/Demo,Robustness,Self-supervised learning,Sensors,sports game,Vibrations,Video on demand,Visualization,Web sites},
  file = {/home/jesse/Zotero/storage/2RJ8S8GI/Chang et al. - 2024 - Poster Abstract Listen and Then Sense Vibration-based Sports Crowd Monitoring by Pre-training with.pdf}
}
% == BibTeX quality report for chang.etal2024PosterAbstract:
% ? Unsure about the formatting of the booktitle
% ? unused Library catalog ("IEEE Xplore")
% ? unused Url ("https://ieeexplore.ieee.org/document/10577402/")

@inproceedings{flohr,
  ids = {codling.etal2024FloHRUbiquitous},
  title = {{{FloHR}}: Ubiquitous Heart Rate Measurement Using Indirect Floor Vibration Sensing},
  shorttitle = {{{FloHR}}},
  booktitle = {Proceedings of the 11th {{ACM International Conference}} on {{Systems}} for {{Energy-efficient Buildings}}, {{Cities}}, and {{Transportation}}},
  author = {Codling, Jesse R. and Shulkin, Jeffrey D. and Chang, Yen-Cheng and Zhang, Jiale and Latapie, Hugo and Noh, Hae Young and Zhang, Pei and Dong, Yiwen},
  year = {2024},
  month = oct,
  series = {{{BuildSys}} '24},
  pages = {44--54},
  publisher = {Association for Computing Machinery},
  address = {Hangzhou China},
  doi = {10.1145/3671127.3698170},
  urldate = {2025-09-11},
  abstract = {Heart rate is one of the most critical metrics for human health. Most common methods for measuring human heart rate involve body contact, whether from wearable devices or manual measurement. However, such devices can cause discomfort to some patients. Past work for non-contact or remote heart rate measurement (e.g., camera or radio) is often limited by line-of-sight requirements that are not always possible in the real-world environment.This paper presents FloHR, an indirect heart rate monitoring system for human beings using heartbeat-induced floor vibrations. The key insight is that the human body generates a small wave of pressure and sound with each heartbeat. These are propagated as vibration through the structures the person is in contact with (e.g., a chair) and through the floor. FloHR then detects and interprets these small floor vibrations. We developed a highly sensitive vibration sensing system and heartbeat pattern modelling to identify these tiny vibrations among other body motions and ambient noise.We evaluated FloHR in a real home environment, demonstrating an average heart rate error similar to medical device standards on the floor near the subjects' chair, and on the order of 10 beats per minute (bpm) on the floor 2 meters away from the subject.},
  isbn = {979-8-4007-0706-3},
  langid = {english},
  language = {en},
  keywords = {feature,Fully-Reviewed Conference,Heart Rate,Vibration},
  file = {/home/jesse/Zotero/storage/4ZWVCLVD/Codling et al. - 2024 - FloHR Ubiquitous Heart Rate Measurement using Indirect Floor Vibration Sensing.pdf}
}
% == BibTeX quality report for flohr:
% ? unused Conference name ("BuildSys '24: The 11th ACM International Conference on Systems for Energy-Efficient Buildings, Cities, and Transportation")
% ? unused Library catalog ("ACM Digital Library")
% ? unused Url ("https://dl.acm.org/doi/10.1145/3671127.3698170")

@article{dong.etal2024ContextawareCrowd,
  title = {Context-Aware Crowd Monitoring for Sports Games Using Crowd-Induced Floor Vibrations},
  author = {Dong, Yiwen and Wu, Yuyan and Chang, Yen-Cheng and Aggarwal, Jatin and Codling, Jesse R. and Latapie, Hugo and Zhang, Pei and Noh, Hae Young},
  year = {2024},
  month = jan,
  journal = {Data-Centric Engineering},
  volume = {5},
  pages = {e25},
  issn = {2632-6736},
  doi = {10.1017/dce.2024.28},
  urldate = {2025-09-11},
  abstract = {Crowd monitoring for sports games is important to improve public safety, game experience, and venue management. Recent crowd-crushing incidents (e.g., the Kanjuruhan Stadium disaster) have caused 100+ deaths, calling for advancements in crowd-monitoring methods. Existing monitoring approaches include manual observation, wearables, video-, audio-, and WiFi-based sensing. However, few meet the practical needs due to their limitations in cost, privacy protection, and accuracy.In this paper, we introduce a novel crowd monitoring method that leverages floor vibrations to infer crowd reactions (e.g., clapping) and traffic (i.e., the number of people entering) in sports stadiums. Our method allows continuous crowd monitoring in a privacy-friendly and cost-effective way. Unlike monitoring one person, crowd monitoring involves a large population, leading to high uncertainty in the vibration data. To overcome the challenge, we bring in the context of crowd behaviors, including (1) temporal context to inform crowd reactions to the highlights of the game and (2) spatial context to inform crowd traffic in relation to the facility layouts. We deployed our system at Stanford Maples Pavilion and Michigan Stadium for real-world evaluation, which shows a 14.7\% and 12.5\% error reduction compared to the baseline methods without the context information.},
  langid = {english},
  language = {en},
  keywords = {context-aware,crowd monitoring,floor vibration,Journal,sports},
  file = {/home/jesse/Zotero/storage/DY649L2R/Dong et al. - 2024 - Context-aware crowd monitoring for sports games using crowd-induced floor vibrations.pdf}
}
% == BibTeX quality report for dong.etal2024ContextawareCrowd:
% ? unused Journal abbreviation ("Data-Centric Eng.")
% ? unused Library catalog ("Cambridge University Press")
% ? unused Url ("https://www.cambridge.org/core/journals/data-centric-engineering/article/contextaware-crowd-monitoring-for-sports-games-using-crowdinduced-floor-vibrations/64C1AB62A8309A74B1E8C55DDF5C1DE4")

@inproceedings{chang.etal2025PosterAbstract,
  title = {Poster Abstract: Leveraging General-Purpose Audio Datasets for Vibration-Based Crowd Monitoring in Stadiums},
  shorttitle = {Poster Abstract},
  booktitle = {Proceedings of the 23rd {{ACM Conference}} on {{Embedded Networked Sensor Systems}}},
  author = {Chang, Yen Cheng and Codling, Jesse and Dong, Yiwen and Zhang, Jiale and Chen, Jiasi and Noh, Hae Young and Zhang, Pei},
  year = {2025},
  month = may,
  pages = {590--591},
  publisher = {ACM},
  address = {UC Irvine Student Center. Irvine CA USA},
  doi = {10.1145/3715014.3724022},
  urldate = {2025-09-11},
  copyright = {All rights reserved},
  isbn = {979-8-4007-1479-5},
  langid = {english},
  language = {en},
  file = {/home/jesse/Zotero/storage/FGGNJMPP/Chang et al. - 2025 - Poster Abstract Leveraging General-Purpose Audio Datasets for Vibration-based Crowd Monitoring in S.pdf}
}
% == BibTeX quality report for chang.etal2025PosterAbstract:
% ? unused Conference name ("SenSys '25: 23rd ACM Conference on Embedded Networked Sensor Systems")
% ? unused Library catalog ("DOI.org (Crossref)")
% ? unused Url ("https://dl.acm.org/doi/10.1145/3715014.3724022")

@inproceedings{codling.etal2025PosterAbstract,
  title = {Poster Abstract: Multiscale Vibration Sensing for Activity and Vital Signs Monitoring in Pig Pens},
  shorttitle = {Poster Abstract},
  booktitle = {Proceedings of the 23rd {{ACM Conference}} on {{Embedded Networked Sensor Systems}}},
  author = {Codling, Jesse R and Shulkin, Jeffrey D and Vibhatasilpin, Abhipol and Adhana, Vedant and Rohrer, Gary and Miles, Jeremy and Sharma, Sudhendu and {Brown-Brandl}, Tami and Noh, Hae Young and Zhang, Pei},
  year = {2025},
  month = may,
  pages = {650--651},
  publisher = {ACM},
  address = {UC Irvine Student Center. Irvine CA USA},
  doi = {10.1145/3715014.3724052},
  urldate = {2025-09-11},
  copyright = {All rights reserved},
  isbn = {979-8-4007-1479-5},
  langid = {english},
  language = {en},
  file = {/home/jesse/Zotero/storage/25X9XWH3/Codling et al. - 2025 - Poster Abstract Multiscale Vibration Sensing for Activity and Vital Signs Monitoring in Pig Pens.pdf}
}
% == BibTeX quality report for codling.etal2025PosterAbstract:
% ? unused Conference name ("SenSys '25: 23rd ACM Conference on Embedded Networked Sensor Systems")
% ? unused Library catalog ("DOI.org (Crossref)")
% ? unused Url ("https://dl.acm.org/doi/10.1145/3715014.3724052")

@inproceedings{zhang.etal2025PosterAbstract,
  title = {Poster Abstract: On-Shelf Weight Difference Estimation through Active Vibration Sensing},
  shorttitle = {Poster Abstract},
  booktitle = {Proceedings of the 23rd {{ACM Conference}} on {{Embedded Networked Sensor Systems}}},
  author = {Zhang, Jiale and Wu, Yuyan and Codling, Jesse and Gersey, Julia and Bannis, Adeola and Dominguez, Carlos Ruiz and Sun, Ke and Zhang, Pei},
  year = {2025},
  month = may,
  pages = {640--641},
  publisher = {ACM},
  address = {UC Irvine Student Center. Irvine CA USA},
  doi = {10.1145/3715014.3724047},
  urldate = {2025-09-11},
  copyright = {All rights reserved},
  isbn = {979-8-4007-1479-5},
  langid = {english},
  language = {en},
  file = {/home/jesse/Zotero/storage/ZAAFRGK9/Zhang et al. - 2025 - Poster Abstract On-Shelf Weight Difference Estimation Through Active Vibration Sensing.pdf}
}
% == BibTeX quality report for zhang.etal2025PosterAbstract:
% ? unused Conference name ("SenSys '25: 23rd ACM Conference on Embedded Networked Sensor Systems")
% ? unused Library catalog ("DOI.org (Crossref)")
% ? unused Url ("https://dl.acm.org/doi/10.1145/3715014.3724047")

@inproceedings{gersey.etal2025PosterAbstract,
  title = {Poster Abstract: Sniffing out the City - Vehicular Multimodal Sensing for Environmental and Infrastructure Analysis},
  shorttitle = {Poster Abstract},
  booktitle = {Proceedings of the 23rd {{ACM Conference}} on {{Embedded Networked Sensor Systems}}},
  author = {Gersey, Julia and Aggarwal, Jatin and Zhang, Jiale and Codling, Jesse and Zhang, Pei},
  year = {2025},
  month = may,
  pages = {632--633},
  publisher = {ACM},
  address = {UC Irvine Student Center. Irvine CA USA},
  doi = {10.1145/3715014.3724043},
  urldate = {2025-09-11},
  copyright = {All rights reserved},
  isbn = {979-8-4007-1479-5},
  langid = {english},
  language = {en},
  file = {/home/jesse/Zotero/storage/CCRMCJ6J/Gersey et al. - 2025 - Poster Abstract Sniffing Out the City - Vehicular Multimodal Sensing for Environmental and Infrastr.pdf}
}
% == BibTeX quality report for gersey.etal2025PosterAbstract:
% ? unused Conference name ("SenSys '25: 23rd ACM Conference on Embedded Networked Sensor Systems")
% ? unused Library catalog ("DOI.org (Crossref)")
% ? unused Url ("https://dl.acm.org/doi/10.1145/3715014.3724043")

@misc{GeoMCU,
  ids = {codling.etal2025GeoMCUAdaptable},
  title = {{{GeoMCU}}: Adaptable and Resilient Low-Noise Sensing Platform for Structural Vibrations},
  shorttitle = {{{GeoMCU}}},
  author = {Codling, Jesse and Dong, Yiwen and Ruiz, Carlos and Bonde, Amelie and Pan, Shijia and Noh, Hae Young and Zhang, Pei},
  year = {2025},
  month = sep,
  publisher = {engrXiv},
  doi = {10.31224/5351},
  urldate = {2025-09-15},
  abstract = {Accurate and scalable structural vibration sensing is an essential tool for a wide range of applications including human and animal health and safety. We present GeoMCU, an open-source, low-noise, sensing platform based around geophones, designed for adaptability and resilience in diverse, real-world environments. GeoMCU builds on an iterative, experience-driven development process to yield an adaptable sensor platform which reduces electrical noise interference, allows flexible sensor deployment, and supports high precision and time synchronization where required. Evaluation of the platform shows a 4{\texttimes} reduction in electrical noise and over a 10{\texttimes} increase in mean time between failures compared to prior solutions. Through multiple field deployments---ranging from livestock health monitoring to human heart rate detection and stadium crowd behavior analysis---GeoMCU~has demonstrated significant advantages in scalability, adaptability, and reliability which present a promising solution for ubiquitous sensing in scientific, industrial, and residential environments.},
  archiveprefix = {engrXiv},
  copyright = {https://creativecommons.org/licenses/by/4.0},
  langid = {english},
  language = {en},
  file = {/home/jesse/Zotero/storage/6IUT5B5E/Codling et al. - 2025 - GeoMCU adaptable and resilient low-noise sensing platform for structural vibrations.pdf}
}
% == BibTeX quality report for GeoMCU:
% ? unused Library catalog ("DOI.org (Crossref)")
% ? unused Url ("https://engrxiv.org/preprint/view/5351/version/7111")

@article{dong.etal2025RobustPiglet,
  title = {Robust Piglet Nursing Behavior Monitoring through Multi-Modal Fusion of Computer Vision and Ambient Floor Vibration},
  author = {Dong, Yiwen and Song, Zihao and Codling, Jesse R. and Rohrer, Gary and Miles, Jeremy and Sharma, Sudhendu and {Brown-Brandl}, Tami and Zhang, Pei and Noh, Hae Young},
  year = {2025},
  month = nov,
  journal = {Computers and Electronics in Agriculture},
  volume = {238},
  pages = {110804},
  issn = {0168-1699},
  doi = {10.1016/j.compag.2025.110804},
  urldate = {2025-09-11},
  abstract = {Nursing is a critical activity during the lactation period of swine farming. Continuous monitoring of piglet nursing behavior during the lactation period is essential to informing animal caretakers about the health status of piglets to reduce the mortality rate, maximize lactational growth, and improve animal welfare. Traditional approaches rely on manual observation and wearable devices, which are labor-intensive and can cause discomfort to the animals. Recent advancement in computer vision and ambient vibration sensing enables non-contact piglet nursing monitoring: The computer vision approach captures piglet location but has limited observation of their detailed movement due to lighting, resolution, and visual obstruction constraints; the ambient vibration sensing approach captures piglet movement patterns but has limited location information. In this study, a novel approach to integrate these two complementary sensing modalities is developed for robust piglet nursing behavior monitoring during the lactation period. This study leverages the state-of-the-art Segment Anything Model (SAM) to first convert images into sparse representations of piglet behaviors and then combine with ambient vibration to collaboratively infer piglet nursing pattern and intensity. This new approach enables piglet nursing monitoring with much lower computing and storage requirements than conventional computer vision methods, making it more practical for farm settings. Real-world experiments were conducted at a pig farm for continuous vision and vibration monitoring of 8 pens over 3 farrowing cycles. This study has a 97\% accuracy in classifying 5 nursing stages, representing a significant 3{\texttimes} and 3.8{\texttimes} error reduction compared to the baseline method using only vision or vibration data, respectively. The multi-modal fusion approach leads to an efficient, robust, and accurate piglet nursing model that can immediately inform caretakers of issues that arise during this crucial time point of a piglet's life.},
  langid = {english},
  language = {en},
  keywords = {Computer vision,Multi-modal,Nursing,Precision livestock farming,Structural vibration},
  file = {/home/jesse/Zotero/storage/DSYNPQPC/Dong et al. - 2025 - Robust piglet nursing behavior monitoring through multi-modal fusion of computer vision and ambient.pdf}
}
% == BibTeX quality report for dong.etal2025RobustPiglet:
% ? unused Journal abbreviation ("Comput. Electron. Agric.")
% ? unused Library catalog ("ScienceDirect")
% ? unused Url ("https://www.sciencedirect.com/science/article/pii/S016816992500910X")
